{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "AAPL_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_AAPL.csv', parse_dates=['Date'])  # Import data from local CSV file to a dataframe.\n",
    "AAPL_df['Symbol'] = 'AAPL'  # Add a column titled \"Symbol\" in the dataframe and append all rows with the stock symbol \"AAPL\".\n",
    "AAPL_df['Open'] = AAPL_df['Open'].str.replace(\"$\",'', regex=True).astype(float)  \n",
    "AAPL_df['High'] = AAPL_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AAPL_df['Low'] = AAPL_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AAPL_df['Close/Last'] = AAPL_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AAPL_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)  \n",
    "AAPL_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/AAPL.csv', index = False)  # Export the dataframe back to CSV file with new file name and remove index.\n",
    "\n",
    "AMD_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_AMD.csv', parse_dates=['Date'])\n",
    "AMD_df['Symbol'] = 'AMD'\n",
    "AMD_df['Open'] = AMD_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMD_df['High'] = AMD_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMD_df['Low'] = AMD_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMD_df['Close/Last'] = AMD_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMD_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "AMD_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/AMD.csv', index = False)\n",
    "\n",
    "AMZN_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_AMZN.csv', parse_dates=['Date'])\n",
    "AMZN_df['Symbol'] = 'AMZN'\n",
    "AMZN_df['Open'] = AMZN_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMZN_df['High'] = AMZN_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMZN_df['Low'] = AMZN_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMZN_df['Close/Last'] = AMZN_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "AMZN_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "AMZN_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/AMZN.csv', index = False)\n",
    "\n",
    "CSCO_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_CSCO.csv', parse_dates=['Date'])\n",
    "CSCO_df['Symbol'] = 'CSCO'\n",
    "CSCO_df['Open'] = CSCO_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "CSCO_df['High'] = CSCO_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "CSCO_df['Low'] = CSCO_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "CSCO_df['Close/Last'] = CSCO_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "CSCO_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "CSCO_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/CSCO.csv', index = False)\n",
    "\n",
    "META_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_META.csv', parse_dates=['Date'])\n",
    "META_df['Symbol'] = 'META'\n",
    "META_df['Open'] = META_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "META_df['High'] = META_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "META_df['Low'] = META_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "META_df['Close/Last'] = META_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "META_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "META_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/META.csv', index = False)\n",
    "\n",
    "MSFT_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_MSFT.csv', parse_dates=['Date'])\n",
    "MSFT_df['Symbol'] = 'MSFT'\n",
    "MSFT_df['Open'] = MSFT_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "MSFT_df['High'] = MSFT_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "MSFT_df['Low'] = MSFT_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "MSFT_df['Close/Last'] = MSFT_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "MSFT_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "MSFT_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/MSFT.csv', index = False)\n",
    "\n",
    "NFLX_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_NFLX.csv', parse_dates=['Date'])\n",
    "NFLX_df['Symbol'] = 'NFLX'\n",
    "NFLX_df['Open'] = NFLX_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "NFLX_df['High'] = NFLX_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "NFLX_df['Low'] = NFLX_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "NFLX_df['Close/Last'] = NFLX_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "NFLX_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "NFLX_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/NFLX.csv', index = False)\n",
    "\n",
    "QCOM_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_QCOM.csv', parse_dates=['Date'])\n",
    "QCOM_df['Symbol'] = 'QCOM'\n",
    "QCOM_df['Open'] = QCOM_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "QCOM_df['High'] = QCOM_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "QCOM_df['Low'] = QCOM_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "QCOM_df['Close/Last'] = QCOM_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "QCOM_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "QCOM_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/QCOM.csv', index = False)\n",
    "\n",
    "SBUX_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_SBUX.csv', parse_dates=['Date'])\n",
    "SBUX_df['Symbol'] = 'SBUX'\n",
    "SBUX_df['Open'] = SBUX_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "SBUX_df['High'] = SBUX_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "SBUX_df['Low'] = SBUX_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "SBUX_df['Close/Last'] = SBUX_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "SBUX_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "SBUX_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/SBUX.csv', index = False)\n",
    "\n",
    "TSLA_df = pd.read_csv('/Users/miked/Downloads/HistoricalData_TSLA.csv', parse_dates=['Date'])\n",
    "TSLA_df['Symbol'] = 'TSLA'\n",
    "TSLA_df['Open'] = TSLA_df['Open'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "TSLA_df['High'] = TSLA_df['High'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "TSLA_df['Low'] = TSLA_df['Low'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "TSLA_df['Close/Last'] = TSLA_df['Close/Last'].str.replace(\"$\",'', regex=True).astype(float)\n",
    "TSLA_df.rename(columns={'Close/Last' : 'Close'}, inplace=True)\n",
    "TSLA_df.to_csv('/Users/miked/documents/Code_Louisville_Project/CL-Data-Main/TSLA.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
